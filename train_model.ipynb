{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LEluokuLs-M"
      },
      "source": [
        "# オートエンコーダを使用した学習処理を実行するプログラム"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pom1w-zzQgFD"
      },
      "source": [
        "## 実行環境のライブラリバージョンの調整\n",
        "\n",
        "演習で使用するライブラリのバージョンをプログラムの内容に合わせて入れ替えます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW5dDnD1RmvT"
      },
      "source": [
        "# tensorflowのバージョンをラズパイの推論処理のプログラム環境に合わせて変更する\n",
        "!pip install tensorflow==1.14.0\n",
        "!pip install tensorboard==1.14.0\n",
        "!pip install tensorflow-estimator==1.14.0\n",
        "!pip install scikit-learn==0.21.2\n",
        "!pip install Keras==2.2.4\n",
        "!pip install Keras-Applications==1.0.8\n",
        "!pip install Keras-Preprocessing==1.1.0\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogxVWonYLs-R"
      },
      "source": [
        "## 必要なモジュールのインポート\n",
        "処理に必要な各種のライブラリモジュールをインポートします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz62wDuOOKVv"
      },
      "source": [
        "# 必要なライブラリのインポート\n",
        "import tensorflow as tf\n",
        "#import tensorflow.contrib.eager as tfe\n",
        "from tensorflow.keras.models import Sequential, Model, save_model\n",
        "from tensorflow.keras.layers import Activation, Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "#import os\n",
        "import numpy as np\n",
        "#import pandas as pd\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt8krTJPLs-N"
      },
      "source": [
        "## Googleドライブのマウント\n",
        "\n",
        "Google Colaboratoryで実行する場合は、Googleドライブをマウントし、ファイルの読み書きを行えるようにします。\n",
        "実行すると、プログラムの下の部分に認証コードを取得するためのリンクが表示されるので、そのリンクをクリックし、必要に応じてGoogleのログイン処理やアクセス許可の処理を行います。その後、認証用のコードが表示されるので、そのコードをコピーしたら、最初に表示されていたリンクの下の入力欄に認証コードを入力してEnterキーを押して下さい。\"Mounted at /content/drive\"と表示されたらマウント処理は完了です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_SyqgCzLs-O"
      },
      "source": [
        "  # Colaboratory上で実行することでGoogleドライブのマウント処理を行う\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  # 作業フォルダのパス\n",
        "  work_path = '/content/drive/My Drive/work/'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--juAx_mLs-V"
      },
      "source": [
        "## 学習用データの読み込み\n",
        "\n",
        "あらかじめ用意した学習用データの読み込みを行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5YN7jNALs-k",
        "scrolled": true
      },
      "source": [
        "filename = work_path + 'training_60s.csv'\n",
        "\n",
        "# csvファイルから元データを読み込む\n",
        "data_train = np.loadtxt(filename, delimiter=',')\n",
        "\n",
        "# 読み込んだデータのサイズを表示\n",
        "print('学習用データ: ', data_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_FAY-SkLs-u"
      },
      "source": [
        "## データの正規化\n",
        "\n",
        "読み込んだデータを正規化します。また、正規化で使用したパラメタ情報は推論時にも必要となるためファイルに保存します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMnse87kLs-v"
      },
      "source": [
        "# 値の範囲を正規化\n",
        "scaler = MinMaxScaler()\n",
        "data_train_std = scaler.fit_transform(data_train)\n",
        "\n",
        "# 正規化に使用したパラメタを推論時に使用するためファイルに保存\n",
        "pickle.dump(scaler, open(work_path+'scaler.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReBN2PHcLs-0"
      },
      "source": [
        "## 訓練用データと検証用データの分割（ホールドアウト法）\n",
        "\n",
        "過学習かどうかを確認できるようにするために、学習用データと検証用データに分割します。全体を8:2で分割します。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pDVgFrKLs-0"
      },
      "source": [
        "# 検証用データの割合を20%として、データを分割する\n",
        "X_trn, X_tst = train_test_split(data_train_std, test_size=0.2)\n",
        "\n",
        "# 分割結果のサイズを表示\n",
        "print('訓練用データ X_trn: ',X_trn.shape)\n",
        "print('検証用データ X_tst: ',X_tst.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6Tdt4HaLs-4"
      },
      "source": [
        "## AutoEncoderモデルの構成を定義\n",
        "\n",
        "学習で使用するAutoEncoderモデルの構成を定義します。\n",
        "レイヤの構成はエンコーダー部とデコーダー部をそれぞれ２層としています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v225BimCLs-5"
      },
      "source": [
        "# AutoEncoderのネットワーク構造を定義\n",
        "model = Sequential() # 層を重ねて定義していくタイプのモデル\n",
        "model.add(Dense(40, input_dim = 40, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(5, activation='relu', name = 'encoder'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(40, activation='sigmoid'))\n",
        "\n",
        "# 学習モデルのコンパイル（実行準備）\n",
        "model.compile(loss = 'mse', optimizer ='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFx9wmEhLs-9"
      },
      "source": [
        "## 学習処理の実行\n",
        "\n",
        "用意したAutoEncoderのモデルと学習用データを使って学習処理を実行します。実行が完了したら、学習済モデルをファイルとして保存します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnH2RaUuLs--",
        "scrolled": true
      },
      "source": [
        "# 学習処理の実行\n",
        "hist = model.fit(X_trn, X_trn, epochs=100, batch_size=128, validation_data=(X_tst, X_tst))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9v5borV7DDg"
      },
      "source": [
        "# 学習済みモデルの保存\n",
        "tf.keras.experimental.export_saved_model(model, 'saved_model', serving_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4RUDVKMCYNW"
      },
      "source": [
        "# 学習済みモデルを転送しやすいように圧縮\n",
        "!tar -zcvf saved_model.tar.gz saved_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習済みモデルをGoogleドライブにコピー\n",
        "!cp saved_model.tar.gz drive/MyDrive/work/"
      ],
      "metadata": {
        "id": "cU4yNz3kss2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMxEKWKRLs_D"
      },
      "source": [
        "## 学習結果の確認\n",
        "\n",
        "学習中の誤差の推移をグラフでプロットし、収束状況や過学習の状況を確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmWItw_SLs_D"
      },
      "source": [
        "# エポック経過にともなう二乗平均誤差の履歴のプロット\n",
        "plt.plot(hist.history['loss'],\"b\",label=\"Training loss\",)\n",
        "plt.plot(hist.history['val_loss'],\"r\",label=\"Validation loss\")\n",
        "plt.title('Loss history')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss, [mse]')\n",
        "plt.legend(loc='upper right')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "以下はテスト用のコードなので本番環境では不要\n",
        "---\n",
        "学習時のmseの値の変化と推論時のmseの値がおおむね一致しているのかどうかを確認するためのコード\n"
      ],
      "metadata": {
        "id": "KyluWmUGX6il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#テストコード\n",
        "\n",
        "output = model.predict(X_tst)"
      ],
      "metadata": {
        "id": "niHBGn69K7Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_trn)"
      ],
      "metadata": {
        "id": "UYyfZx_ROY-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {
        "id": "y7xLfiKVPDnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 以下で計算したら大体あっていた　2022/3/4 11:30\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mse = mean_squared_error(X_tst, output)"
      ],
      "metadata": {
        "id": "8C_WkJhvLUYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = tf.keras.metrics.mean_squared_error(X_trn, output)"
      ],
      "metadata": {
        "id": "T7Amlzn4MJbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mse)"
      ],
      "metadata": {
        "id": "BIr3bmB2Lhsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UD553hx1mAjW"
      },
      "source": [
        "import pkg_resources\n",
        "for dist in pkg_resources.working_set:\n",
        "  print(dist)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}